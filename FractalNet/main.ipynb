{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is implementation of [FractalNet](http://arxiv.org/abs/1605.07648) paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-06-02T00:39:16.713335",
     "start_time": "2016-06-02T00:39:16.001944"
    },
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def noPaths(n):\n",
    "    \"\"\"\n",
    "        Returns number of path with C=n\n",
    "    \"\"\"\n",
    "    # Lazy recurrsion... yeah it could be optimized, but meh.\n",
    "    if n <= 1:\n",
    "        return 1\n",
    "    return 1 + noPaths(n-1)**2\n",
    "\n",
    "def pmfPaths(n):\n",
    "    pdf = np.array(\n",
    "        [noPaths(x) for x in range(1, n+1)],\n",
    "        dtype=np.float32\n",
    "    )\n",
    "    pdf /= np.sum(pdf) # Normalizing\n",
    "    return stats.rv_discrete(values=(range(n), pdf))\n",
    "\n",
    "    \n",
    "class FractalNet():\n",
    "    def __init__(self, input, n, f_height = 3, f_width = 3):\n",
    "        _, _, _, c = input.get_shape()\n",
    "        f_channels = int(c)\n",
    "        self.n = n \n",
    "        self.pmf = pmfPaths(n)\n",
    "        self.children = []\n",
    "        with tf.name_scope(\"F%d\" % n) as scope:\n",
    "            # Convolutional layer filter\n",
    "            self.filter = tf.Variable(tf.truncated_normal(\n",
    "                [f_height, f_width, f_channels, f_channels], stddev=0.35),\n",
    "                name=\"weights\")\n",
    "            \n",
    "            # activations in join layer \n",
    "            # for mean join layer they should be equal and sum to 1\n",
    "            self.is_active = [\n",
    "                tf.Variable(1.0/n, trainable=False, name=\"a%d\"%i)\n",
    "                for i in range(n)\n",
    "            ] \n",
    "            self.__tensors = [\n",
    "                tf.nn.conv2d(input, self.filter, [1,1,1,1], 'SAME')\n",
    "            ]\n",
    "            if n > 1:\n",
    "                Fp = FractalNet(input, n - 1, f_height, f_width)\n",
    "                self.children.append(Fp)\n",
    "                Fp = FractalNet(Fp.get_tensor(), n - 1, f_height, f_width)\n",
    "                self.children.append(Fp)\n",
    "                self.__tensors.extend(Fp.__tensors)\n",
    "                \n",
    "            self.__tensor = tf.add_n(\n",
    "                [tf.mul(m, x) for m, x in zip(self.is_active, self.__tensors)], \n",
    "                name=\"Join\"\n",
    "            )\n",
    "\n",
    "    def get_tensor(self):\n",
    "        return self.__tensor\n",
    "\n",
    "    def gen_drop_path(self):\n",
    "        \"\"\"\n",
    "            Randomly pick path in network and drop all others\n",
    "        \"\"\"\n",
    "        active_path = self.pmf.rvs() # Uniformly choose path\n",
    "        assert 0 <= active_path < len(self.is_active) # Sanity check\n",
    "        \n",
    "        # Recursively select only one activation path through the network\n",
    "        # This does a bit more...since in each pooling layer, only one input\n",
    "        # is accepted, therefore there would be some useless half-path from \n",
    "        # source, but not reaching the sink. It's only to simplyfy the\n",
    "        # implementation.\n",
    "        return tf.group(*[\n",
    "            var.assign(1 if i == active_path else 0)\n",
    "            for i, var in enumerate(self.is_active)\n",
    "        ], *[fp.gen_drop_path() for fp in self.children])\n",
    "\n",
    "    def set_test(self):\n",
    "        \"\"\"\n",
    "            Kills any droppaths set\n",
    "        \"\"\"\n",
    "        return tf.group(*[\n",
    "            var.assign(1.0/self.n) \n",
    "            for var in self.is_active\n",
    "        ])\n",
    "\n",
    "height, width, channels = 28, 28, 1\n",
    "noClasses = 10\n",
    "    \n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    X = tf.placeholder(tf.float32, [None, height, width, channels])\n",
    "    Y = tf.placeholder(tf.float32, [None, noClasses])\n",
    "    \n",
    "    F = FractalNet(X, 3)\n",
    "    \n",
    "    net = F.get_tensor()\n",
    "    net = tflearn.fully_connected(net, noClasses)\n",
    "    yp = tf.nn.softmax(net)\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(yp, net)\n",
    "    \n",
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    merged = tf.merge_all_summaries()\n",
    "    writer = tf.train.SummaryWriter(\"/tmp/FractalNet\", sess.graph)\n",
    "    sess.run(F.gen_drop_path())\n",
    "    sess.run(F.set_test())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
